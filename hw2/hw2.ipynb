{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd5d6cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black \\n# \\u0440\\u0435\\u0434\\u0430\\u043a\\u0442\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u0438\\u0435 \\u044f\\u0447\\u0435\\u0435\\u043a \\u043f\\u043e \\u0441\\u0442\\u0430\\u043d\\u0434\\u0430\\u0440\\u0442\\u0430\\u043c pep8\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n# \\u0440\\u0435\\u0434\\u0430\\u043a\\u0442\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u0438\\u0435 \\u044f\\u0447\\u0435\\u0435\\u043a \\u043f\\u043e \\u0441\\u0442\\u0430\\u043d\\u0434\\u0430\\u0440\\u0442\\u0430\\u043c pep8\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "# редактирование ячеек по стандартам pep8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989888fb",
   "metadata": {},
   "source": [
    "## Загрузка парсеров и sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a9c2b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ru-core-news-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.4.0/ru_core_news_sm-3.4.0-py3-none-any.whl (15.3 MB)\n",
      "     -------------------------------------- 15.3/15.3 MB 391.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pymorphy2>=0.9 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ru-core-news-sm==3.4.0) (0.9.1)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ru-core-news-sm==3.4.0) (3.4.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2>=0.9->ru-core-news-sm==3.4.0) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2>=0.9->ru-core-news-sm==3.4.0) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2>=0.9->ru-core-news-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (8.1.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (58.1.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.23.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.1.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.4.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (4.64.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (4.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2022.6.15)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.0.1)\n",
      "Requirement already satisfied: blis<0.10.0,>=0.7.8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.9.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('ru_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9230718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting natasha\n",
      "  Downloading natasha-1.4.0-py3-none-any.whl (34.4 MB)\n",
      "     ---------------------------------------- 34.4/34.4 MB 2.3 MB/s eta 0:00:00\n",
      "Collecting navec>=0.9.0\n",
      "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pymorphy2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from natasha) (0.9.1)\n",
      "Collecting ipymarkup>=0.8.0\n",
      "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
      "Collecting razdel>=0.5.0\n",
      "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
      "Collecting yargy>=0.14.0\n",
      "  Downloading yargy-0.15.0-py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 41.1/41.1 KB 1.9 MB/s eta 0:00:00\n",
      "Collecting slovnet>=0.3.0\n",
      "  Downloading slovnet-0.5.0-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 49.4/49.4 KB 2.6 MB/s eta 0:00:00\n",
      "Collecting intervaltree>=3\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from navec>=0.9.0->natasha) (1.23.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2->natasha) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2->natasha) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
      "Collecting sortedcontainers<3.0,>=2.0\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Building wheels for collected packages: intervaltree\n",
      "  Building wheel for intervaltree (setup.py): started\n",
      "  Building wheel for intervaltree (setup.py): finished with status 'done'\n",
      "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26119 sha256=1c7333882dcbcccd2f4d49a599a41138fe7edeaad4dd105574dff0bb54da5c6f\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\fa\\80\\8c\\43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n",
      "Successfully built intervaltree\n",
      "Installing collected packages: sortedcontainers, razdel, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
      "Successfully installed intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 razdel-0.5.0 slovnet-0.5.0 sortedcontainers-2.4.0 yargy-0.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eff1721a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2) (0.6.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5a889e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sklearn) (1.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5445b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\nfrom sklearn.metrics import accuracy_score\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\nfrom sklearn.metrics import accuracy_score\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a180e",
   "metadata": {},
   "source": [
    "## О создании корпуса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e59704",
   "metadata": {},
   "source": [
    "В корпус я включала преимущественно предложения, в которых нужно разрешать грамматическую омонимию (а именно нужно верно отнести слова вроде \"мой\", \"стали\", \"течь\" и т. д. к нужной части речи, что может составлять трудность для парсеров) (я просто гуглила что-то вроде \"примеры грамматической омонимии\" и \"упражнения на разрешение грамматической омонимии для школьников\" и вставляла в текстовый файл то, что подходит именно для проверки правильности частеречной разметки). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d2b56",
   "metadata": {},
   "source": [
    "## Парсинг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8c3d51",
   "metadata": {},
   "source": [
    "Парсинг с помощью SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09151065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"import spacy\\nimport pandas as pd\";\n",
       "                var nbb_formatted_code = \"import spacy\\nimport pandas as pd\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc57405a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"with open(\\\"corpus.txt\\\", \\\"r\\\", encoding = \\\"utf-8\\\") as f:\\n    text = f.read()\\n    \\nnlp = spacy.load(\\\"ru_core_news_sm\\\")\\ndoc = nlp(text)\";\n",
       "                var nbb_formatted_code = \"with open(\\\"corpus.txt\\\", \\\"r\\\", encoding=\\\"utf-8\\\") as f:\\n    text = f.read()\\n\\nnlp = spacy.load(\\\"ru_core_news_sm\\\")\\ndoc = nlp(text)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c3bcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"tokens = []\\npos = []\\nfor token in doc:\\n    tokens.append(token)\\n    pos.append(token.pos_)\\n    \\nlist_tuples = list(zip(tokens, pos))\\ndf = pd.DataFrame(list_tuples, columns=['Tokens', 'POS'])\\ndf.to_csv(\\\"pos_spacy\\\", sep='\\\\t')\";\n",
       "                var nbb_formatted_code = \"tokens = []\\npos = []\\nfor token in doc:\\n    tokens.append(token)\\n    pos.append(token.pos_)\\n\\nlist_tuples = list(zip(tokens, pos))\\ndf = pd.DataFrame(list_tuples, columns=[\\\"Tokens\\\", \\\"POS\\\"])\\ndf.to_csv(\\\"pos_spacy\\\", sep=\\\"\\\\t\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = []\n",
    "pos = []\n",
    "for token in doc:\n",
    "    tokens.append(token)\n",
    "    pos.append(token.pos_)\n",
    "\n",
    "list_tuples = list(zip(tokens, pos))\n",
    "df = pd.DataFrame(list_tuples, columns=[\"Tokens\", \"POS\"])\n",
    "df.to_csv(\"pos_spacy\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c592f058",
   "metadata": {},
   "source": [
    "Парсинг с помощью pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89a4a61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"import pymorphy2\\nmorph = pymorphy2.MorphAnalyzer()\";\n",
       "                var nbb_formatted_code = \"import pymorphy2\\n\\nmorph = pymorphy2.MorphAnalyzer()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pymorphy2\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e60ca5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"tokens = []\\npos = []\\n\\nfor token in doc:\\n    tokens.append(token.text)\\n    pos.append(morph.parse(token.text)[0].tag.POS)\\n    \\nlist_tuples = list(zip(tokens, pos))\\ndf = pd.DataFrame(list_tuples, columns=['Tokens', 'POS'])\\ndf.to_csv(\\\"pos_pymorphy\\\", sep='\\\\t')\";\n",
       "                var nbb_formatted_code = \"tokens = []\\npos = []\\n\\nfor token in doc:\\n    tokens.append(token.text)\\n    pos.append(morph.parse(token.text)[0].tag.POS)\\n\\nlist_tuples = list(zip(tokens, pos))\\ndf = pd.DataFrame(list_tuples, columns=[\\\"Tokens\\\", \\\"POS\\\"])\\ndf.to_csv(\\\"pos_pymorphy\\\", sep=\\\"\\\\t\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = []\n",
    "pos = []\n",
    "\n",
    "for token in doc:\n",
    "    tokens.append(token.text)\n",
    "    pos.append(morph.parse(token.text)[0].tag.POS)\n",
    "\n",
    "list_tuples = list(zip(tokens, pos))\n",
    "df = pd.DataFrame(list_tuples, columns=[\"Tokens\", \"POS\"])\n",
    "df.to_csv(\"pos_pymorphy\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7600fc37",
   "metadata": {},
   "source": [
    "Парсинг с помощью natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c1f2899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"from natasha import (\\n    Segmenter,\\n    NewsEmbedding,\\n    NewsMorphTagger,\\n    Doc\\n)\\n\\nsegmenter = Segmenter()\\nemb = NewsEmbedding()\\nmorph_tagger = NewsMorphTagger(emb)\";\n",
       "                var nbb_formatted_code = \"from natasha import Segmenter, NewsEmbedding, NewsMorphTagger, Doc\\n\\nsegmenter = Segmenter()\\nemb = NewsEmbedding()\\nmorph_tagger = NewsMorphTagger(emb)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from natasha import Segmenter, NewsEmbedding, NewsMorphTagger, Doc\n",
    "\n",
    "segmenter = Segmenter()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7288c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"doc_2 = Doc(text)\\ndoc_2.segment(segmenter)\\ndoc_2.tag_morph(morph_tagger)\\n\\ntokens = []\\npos = []\\nfor token in doc_2.tokens:\\n    tokens.append(token.text)\\n    pos.append(token.pos)\\n    \\nlist_tuples = list(zip(tokens, pos))\\ndf = pd.DataFrame(list_tuples, columns=['Tokens', 'POS'])\\ndf.to_csv(\\\"pos_natasha\\\", sep='\\\\t')\";\n",
       "                var nbb_formatted_code = \"doc_2 = Doc(text)\\ndoc_2.segment(segmenter)\\ndoc_2.tag_morph(morph_tagger)\\n\\ntokens = []\\npos = []\\nfor token in doc_2.tokens:\\n    tokens.append(token.text)\\n    pos.append(token.pos)\\n\\nlist_tuples = list(zip(tokens, pos))\\ndf = pd.DataFrame(list_tuples, columns=[\\\"Tokens\\\", \\\"POS\\\"])\\ndf.to_csv(\\\"pos_natasha\\\", sep=\\\"\\\\t\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_2 = Doc(text)\n",
    "doc_2.segment(segmenter)\n",
    "doc_2.tag_morph(morph_tagger)\n",
    "\n",
    "tokens = []\n",
    "pos = []\n",
    "for token in doc_2.tokens:\n",
    "    tokens.append(token.text)\n",
    "    pos.append(token.pos)\n",
    "\n",
    "list_tuples = list(zip(tokens, pos))\n",
    "df = pd.DataFrame(list_tuples, columns=[\"Tokens\", \"POS\"])\n",
    "df.to_csv(\"pos_natasha\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b80393e",
   "metadata": {},
   "source": [
    "## Конвертация тегов в один стандарт"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3686fa13",
   "metadata": {},
   "source": [
    "В ручной разметке я воспользовалась немного изменённым инвентарём Universal Dependencies (все союзы разметила тегом CONJ, не размечала отдельно имена собственные, никакие глаголы не размеяала как вспомогательные, т. е. тегом AUX). За основу взяла именно Universal Dependencies, а не OpenCorpora, потому что этот инвентарь, во-первых, используется гораздо шире, а во-вторых, меньше, чем OpenCorpora. Это, на мой взгляд, преимущество этого инвентаря для данной задачи, потому что нам больше хочется посмотреть на то, отличит ли парсер существительное / местоимение от глагола, чем на то, отличит ли он инфинитив от неинфинитива."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50584f2",
   "metadata": {},
   "source": [
    "###### Функция конвертации для spacy и natasha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5980f697",
   "metadata": {},
   "source": [
    "Так как при ручной разметке ориентировалась на UD, здесь всё просто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b3a0dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"def ud_tags_converter(file):\\n    tags_dict = {\\\"PROPN\\\":\\\"NOUN\\\", \\\"AUX\\\": \\\"VERB\\\", \\\"SCONJ\\\": \\\"CONJ\\\", \\\"CCONJ\\\": \\\"CONJ\\\"}\\n    with open(file, \\\"r\\\", encoding = \\\"utf-8\\\") as f:\\n        text = f.read()\\n        for key in tags_dict:\\n            text = text.replace(key, tags_dict[key])\\n    with open(file, \\\"w\\\", encoding = \\\"utf-8\\\") as f:\\n        f.write(text)\";\n",
       "                var nbb_formatted_code = \"def ud_tags_converter(file):\\n    tags_dict = {\\\"PROPN\\\": \\\"NOUN\\\", \\\"AUX\\\": \\\"VERB\\\", \\\"SCONJ\\\": \\\"CONJ\\\", \\\"CCONJ\\\": \\\"CONJ\\\"}\\n    with open(file, \\\"r\\\", encoding=\\\"utf-8\\\") as f:\\n        text = f.read()\\n        for key in tags_dict:\\n            text = text.replace(key, tags_dict[key])\\n    with open(file, \\\"w\\\", encoding=\\\"utf-8\\\") as f:\\n        f.write(text)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ud_tags_converter(file):\n",
    "    tags_dict = {\"PROPN\": \"NOUN\", \"AUX\": \"VERB\", \"SCONJ\": \"CONJ\", \"CCONJ\": \"CONJ\"}\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        for key in tags_dict:\n",
    "            text = text.replace(key, tags_dict[key])\n",
    "    with open(file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a170e1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"ud_tags_converter(\\\"pos_natasha\\\")\";\n",
       "                var nbb_formatted_code = \"ud_tags_converter(\\\"pos_natasha\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ud_tags_converter(\"pos_natasha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "848f965a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"ud_tags_converter(\\\"pos_spacy\\\")\";\n",
       "                var nbb_formatted_code = \"ud_tags_converter(\\\"pos_spacy\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ud_tags_converter(\"pos_spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6845d5",
   "metadata": {},
   "source": [
    "###### Функция конвертации для pymorphy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a19cd",
   "metadata": {},
   "source": [
    "Здесь нужно не просто заменить теги, нужно также отловить притяжательные местоимения, которые размечаются тем же тегом, что и полные имена прилагательные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4573a414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"def oc_tags_converter(file):\\n    tags_dict = {\\\"ADJF\\\": \\\"ADJ\\\", \\\"ADJS\\\": \\\"ADJ\\\", \\\"COMP\\\": \\\"ADJ\\\", \\\"INFN\\\": \\\"VERB\\\", \\\"PRTF\\\": \\\"VERB\\\", \\\"PRTS\\\": \\\"VERB\\\", \\\"GRND\\\": \\\"VERB\\\", \\n                 \\\"NUMR\\\": \\\"NUM\\\", \\\"ADVB\\\": \\\"ADV\\\", \\\"NPRO\\\": \\\"PRON\\\", \\\"PRED\\\": \\\"ADV\\\", \\\"PREP\\\": \\\"ADP\\\", \\\"PRCL\\\": \\\"PART\\\"}\\n    with open(file, \\\"r\\\", encoding = \\\"utf-8\\\") as f:\\n        text = f.readlines()\\n        for i in range(len(text)): # \\u0441\\u043c\\u0435\\u043d\\u0430 \\u0442\\u0435\\u0433\\u0430 \\u0443 \\u043c\\u0435\\u0441\\u0442\\u043e\\u0438\\u043c\\u0451\\u043d\\u043d\\u044b\\u0445 \\u043f\\u0440\\u0438\\u043b\\u0430\\u0433\\u0430\\u0442\\u0435\\u043b\\u044c\\u043d\\u044b\\u0445\\n            if \\\"ADJF\\\" in text[i]:\\n                if \\\"Apro\\\" in morph.parse(text[i].split(\\\"\\\\t\\\")[1])[0].tag: # Apro \\u2014 \\u0433\\u0440\\u0430\\u043c\\u043c\\u0435\\u043c\\u0430 \\u0434\\u043b\\u044f \\u043c\\u0435\\u0441\\u0442\\u043e\\u0438\\u043c\\u0451\\u043d\\u043d\\u044b\\u0445 \\u043f\\u0440\\u0438\\u043b\\u0430\\u0433\\u0430\\u0442\\u0435\\u043b\\u044c\\u043d\\u044b\\u0445\\n                    text[i] = text[i].replace(\\\"ADJF\\\", \\\"DET\\\")\\n            for key in tags_dict: # \\u0441\\u043c\\u0435\\u043d\\u0430 \\u043e\\u0441\\u0442\\u0430\\u043b\\u044c\\u043d\\u044b\\u0445 \\u0442\\u0435\\u0433\\u043e\\u0432\\n                try:\\n                    text[i] = text[i].replace(key, tags_dict[key])\\n                except:\\n                    continue\\n    with open(file, \\\"w\\\", encoding = \\\"utf-8\\\") as f:\\n        f.write(\\\"\\\".join(text))\";\n",
       "                var nbb_formatted_code = \"def oc_tags_converter(file):\\n    tags_dict = {\\n        \\\"ADJF\\\": \\\"ADJ\\\",\\n        \\\"ADJS\\\": \\\"ADJ\\\",\\n        \\\"COMP\\\": \\\"ADJ\\\",\\n        \\\"INFN\\\": \\\"VERB\\\",\\n        \\\"PRTF\\\": \\\"VERB\\\",\\n        \\\"PRTS\\\": \\\"VERB\\\",\\n        \\\"GRND\\\": \\\"VERB\\\",\\n        \\\"NUMR\\\": \\\"NUM\\\",\\n        \\\"ADVB\\\": \\\"ADV\\\",\\n        \\\"NPRO\\\": \\\"PRON\\\",\\n        \\\"PRED\\\": \\\"ADV\\\",\\n        \\\"PREP\\\": \\\"ADP\\\",\\n        \\\"PRCL\\\": \\\"PART\\\",\\n    }\\n    with open(file, \\\"r\\\", encoding=\\\"utf-8\\\") as f:\\n        text = f.readlines()\\n        for i in range(len(text)):  # \\u0441\\u043c\\u0435\\u043d\\u0430 \\u0442\\u0435\\u0433\\u0430 \\u0443 \\u043c\\u0435\\u0441\\u0442\\u043e\\u0438\\u043c\\u0451\\u043d\\u043d\\u044b\\u0445 \\u043f\\u0440\\u0438\\u043b\\u0430\\u0433\\u0430\\u0442\\u0435\\u043b\\u044c\\u043d\\u044b\\u0445\\n            if \\\"ADJF\\\" in text[i]:\\n                if (\\n                    \\\"Apro\\\" in morph.parse(text[i].split(\\\"\\\\t\\\")[1])[0].tag\\n                ):  # Apro \\u2014 \\u0433\\u0440\\u0430\\u043c\\u043c\\u0435\\u043c\\u0430 \\u0434\\u043b\\u044f \\u043c\\u0435\\u0441\\u0442\\u043e\\u0438\\u043c\\u0451\\u043d\\u043d\\u044b\\u0445 \\u043f\\u0440\\u0438\\u043b\\u0430\\u0433\\u0430\\u0442\\u0435\\u043b\\u044c\\u043d\\u044b\\u0445\\n                    text[i] = text[i].replace(\\\"ADJF\\\", \\\"DET\\\")\\n            for key in tags_dict:  # \\u0441\\u043c\\u0435\\u043d\\u0430 \\u043e\\u0441\\u0442\\u0430\\u043b\\u044c\\u043d\\u044b\\u0445 \\u0442\\u0435\\u0433\\u043e\\u0432\\n                try:\\n                    text[i] = text[i].replace(key, tags_dict[key])\\n                except:\\n                    continue\\n    with open(file, \\\"w\\\", encoding=\\\"utf-8\\\") as f:\\n        f.write(\\\"\\\".join(text))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def oc_tags_converter(file):\n",
    "    tags_dict = {\n",
    "        \"ADJF\": \"ADJ\",\n",
    "        \"ADJS\": \"ADJ\",\n",
    "        \"COMP\": \"ADJ\",\n",
    "        \"INFN\": \"VERB\",\n",
    "        \"PRTF\": \"VERB\",\n",
    "        \"PRTS\": \"VERB\",\n",
    "        \"GRND\": \"VERB\",\n",
    "        \"NUMR\": \"NUM\",\n",
    "        \"ADVB\": \"ADV\",\n",
    "        \"NPRO\": \"PRON\",\n",
    "        \"PRED\": \"ADV\",\n",
    "        \"PREP\": \"ADP\",\n",
    "        \"PRCL\": \"PART\",\n",
    "    }\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.readlines()\n",
    "        for i in range(len(text)):  # смена тега у местоимённых прилагательных\n",
    "            if \"ADJF\" in text[i]:\n",
    "                if (\n",
    "                    \"Apro\" in morph.parse(text[i].split(\"\\t\")[1])[0].tag\n",
    "                ):  # Apro — граммема для местоимённых прилагательных\n",
    "                    text[i] = text[i].replace(\"ADJF\", \"DET\")\n",
    "            for key in tags_dict:  # смена остальных тегов\n",
    "                try:\n",
    "                    text[i] = text[i].replace(key, tags_dict[key])\n",
    "                except:\n",
    "                    continue\n",
    "    with open(file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c6bcaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"oc_tags_converter(\\\"pos_pymorphy\\\")\";\n",
       "                var nbb_formatted_code = \"oc_tags_converter(\\\"pos_pymorphy\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oc_tags_converter(\"pos_pymorphy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bc7b60",
   "metadata": {},
   "source": [
    "## Подсчёт accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceb85406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"from sklearn.metrics import accuracy_score\";\n",
       "                var nbb_formatted_code = \"from sklearn.metrics import accuracy_score\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43721050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"def accuracy(file):\\n    manual_tagging_df = pd.read_csv(\\\"pos_tagging.csv\\\", sep=\\\",\\\")\\n    manual_tagging = list(manual_tagging_df[\\\"POS\\\"])\\n    parser_tagging_df = pd.read_csv(file, sep=\\\"\\\\t\\\")\\n    parser_tagging = list(parser_tagging_df[\\\"POS\\\"])\\n    print(\\\"Accuracy: %.4f\\\" % accuracy_score(parser_tagging, manual_tagging))\";\n",
       "                var nbb_formatted_code = \"def accuracy(file):\\n    manual_tagging_df = pd.read_csv(\\\"pos_tagging.csv\\\", sep=\\\",\\\")\\n    manual_tagging = list(manual_tagging_df[\\\"POS\\\"])\\n    parser_tagging_df = pd.read_csv(file, sep=\\\"\\\\t\\\")\\n    parser_tagging = list(parser_tagging_df[\\\"POS\\\"])\\n    print(\\\"Accuracy: %.4f\\\" % accuracy_score(parser_tagging, manual_tagging))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def accuracy(file):\n",
    "    manual_tagging_df = pd.read_csv(\"pos_tagging.csv\", sep=\",\")\n",
    "    manual_tagging = list(manual_tagging_df[\"POS\"])\n",
    "    parser_tagging_df = pd.read_csv(file, sep=\"\\t\")\n",
    "    parser_tagging = list(parser_tagging_df[\"POS\"])\n",
    "    print(\"Accuracy: %.4f\" % accuracy_score(parser_tagging, manual_tagging))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c68cf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8607\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"accuracy(\\\"pos_natasha\\\")\";\n",
       "                var nbb_formatted_code = \"accuracy(\\\"pos_natasha\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy(\"pos_natasha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8580f4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"accuracy(\\\"pos_spacy\\\")\";\n",
       "                var nbb_formatted_code = \"accuracy(\\\"pos_spacy\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy(\"pos_spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2720daf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6821\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"accuracy(\\\"pos_pymorphy\\\")\";\n",
       "                var nbb_formatted_code = \"accuracy(\\\"pos_pymorphy\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy(\"pos_pymorphy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47643a86",
   "metadata": {},
   "source": [
    "Лучше всего с задачей справляется SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c38b32",
   "metadata": {},
   "source": [
    "## Чанкер"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47f519d",
   "metadata": {},
   "source": [
    "Мы будем выделять следующие типы n-грамм:\n",
    "1. ADV + ADJ (very nice), так как если прилагательное используется вместе с наречием, то, скорее всего, тональность прилагательного усиливается, что было бы хорошо учесть (вероятно, будет отдельно считаться и прилагательное, и сочетание \"наречие + это же прилагательное\", что, на мой взгляд, далеко не минус)\n",
    "2. Not + ADJ (not exciting), так как частица not меняет смысл на противоположный\n",
    "3. Not + VERB ((does) not work), так как можно дать оценку чему-то, используя глагол с отрицательной частицей (достаточно сказать \"игра не запускается\", чтобы это можно было считать отрицательным отзывом)\n",
    "\n",
    "В качестве парсера будем использовать spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92f60056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"nlp = spacy.load(\\\"en_core_web_sm\\\")\";\n",
       "                var nbb_formatted_code = \"nlp = spacy.load(\\\"en_core_web_sm\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d983f63",
   "metadata": {},
   "source": [
    "Внесём изменения в функцию, отвечающую за препроцессинг:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d07b711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"def preprocessing_with_bigrams(list): # \\u043c\\u044b \\u0440\\u0430\\u0431\\u043e\\u0442\\u0430\\u0435\\u043c \\u0441\\u043e \\u0441\\u043f\\u0438\\u0441\\u043a\\u0430\\u043c\\u0438, \\u0443\\u0434\\u043e\\u0431\\u043d\\u0435\\u0435 \\u043d\\u0430\\u043f\\u0438\\u0441\\u0430\\u0442\\u044c \\u0444\\u0443\\u043d\\u043a\\u0446\\u0438\\u044e, \\u043d\\u0430 \\u0432\\u0445\\u043e\\u0434 \\u043a\\u043e\\u0442\\u043e\\u0440\\u043e\\u0439 \\u043c\\u043e\\u0436\\u043d\\u043e \\u0441\\u0440\\u0430\\u0437\\u0443 \\u043f\\u043e\\u0434\\u0430\\u0442\\u044c \\u0441\\u043f\\u0438\\u0441\\u043e\\u043a\\n    preprocessed_words = []\\n    bigrams = {\\\"ADJ\\\": [\\\"ADV\\\", \\\"not\\\"], \\\"VERB\\\": \\\"not\\\"}\\n    for text in list:\\n        preprocessed_text = nlp(text.lower()) # \\u0437\\u0434\\u0435\\u0441\\u044c \\u0442\\u0435\\u043a\\u0441\\u0442 \\u0443\\u0436\\u0435 \\u0434\\u0435\\u043b\\u0438\\u0442\\u0441\\u044f \\u043f\\u043e \\u043f\\u0440\\u0435\\u0434\\u043b\\u043e\\u0436\\u0435\\u043d\\u0438\\u044f\\u043c \\u0438 \\u0442\\u043e\\u043a\\u0435\\u043d\\u0438\\u0437\\u0438\\u0440\\u0443\\u0435\\u0442\\u0441\\u044f\\n        tokens = [token for token in preprocessed_text if not token.is_punct]\\n        for i in range(len(tokens)):\\n            if tokens[i].lemma_.isalpha:\\n                preprocessed_words.append(tokens[i].lemma_)\\n            if tokens[i].pos_ in bigrams:\\n                if tokens[i-1].pos_ in bigrams[tokens[i].pos_] or tokens[i-1].lemma_ in bigrams[tokens[i].pos_]:\\n                    preprocessed_words.append(tokens[i-1].lemma_ + \\\" \\\" + tokens[i].lemma_)\\n    return preprocessed_words\";\n",
       "                var nbb_formatted_code = \"def preprocessing_with_bigrams(\\n    list,\\n):  # \\u043c\\u044b \\u0440\\u0430\\u0431\\u043e\\u0442\\u0430\\u0435\\u043c \\u0441\\u043e \\u0441\\u043f\\u0438\\u0441\\u043a\\u0430\\u043c\\u0438, \\u0443\\u0434\\u043e\\u0431\\u043d\\u0435\\u0435 \\u043d\\u0430\\u043f\\u0438\\u0441\\u0430\\u0442\\u044c \\u0444\\u0443\\u043d\\u043a\\u0446\\u0438\\u044e, \\u043d\\u0430 \\u0432\\u0445\\u043e\\u0434 \\u043a\\u043e\\u0442\\u043e\\u0440\\u043e\\u0439 \\u043c\\u043e\\u0436\\u043d\\u043e \\u0441\\u0440\\u0430\\u0437\\u0443 \\u043f\\u043e\\u0434\\u0430\\u0442\\u044c \\u0441\\u043f\\u0438\\u0441\\u043e\\u043a\\n    preprocessed_words = []\\n    bigrams = {\\\"ADJ\\\": [\\\"ADV\\\", \\\"not\\\"], \\\"VERB\\\": \\\"not\\\"}\\n    for text in list:\\n        preprocessed_text = nlp(\\n            text.lower()\\n        )  # \\u0437\\u0434\\u0435\\u0441\\u044c \\u0442\\u0435\\u043a\\u0441\\u0442 \\u0443\\u0436\\u0435 \\u0434\\u0435\\u043b\\u0438\\u0442\\u0441\\u044f \\u043f\\u043e \\u043f\\u0440\\u0435\\u0434\\u043b\\u043e\\u0436\\u0435\\u043d\\u0438\\u044f\\u043c \\u0438 \\u0442\\u043e\\u043a\\u0435\\u043d\\u0438\\u0437\\u0438\\u0440\\u0443\\u0435\\u0442\\u0441\\u044f\\n        tokens = [token for token in preprocessed_text if not token.is_punct]\\n        for i in range(len(tokens)):\\n            if tokens[i].lemma_.isalpha:\\n                preprocessed_words.append(tokens[i].lemma_)\\n            if tokens[i].pos_ in bigrams:\\n                if (\\n                    tokens[i - 1].pos_ in bigrams[tokens[i].pos_]\\n                    or tokens[i - 1].lemma_ in bigrams[tokens[i].pos_]\\n                ):\\n                    preprocessed_words.append(\\n                        tokens[i - 1].lemma_ + \\\" \\\" + tokens[i].lemma_\\n                    )\\n    return preprocessed_words\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocessing_with_bigrams(\n",
    "    list,\n",
    "):  # мы работаем со списками, удобнее написать функцию, на вход которой можно сразу подать список\n",
    "    preprocessed_words = []\n",
    "    bigrams = {\"ADJ\": [\"ADV\", \"not\"], \"VERB\": \"not\"}\n",
    "    for text in list:\n",
    "        preprocessed_text = nlp(\n",
    "            text.lower()\n",
    "        )  # здесь текст уже делится по предложениям и токенизируется\n",
    "        tokens = [token for token in preprocessed_text if not token.is_punct]\n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i].lemma_.isalpha:\n",
    "                preprocessed_words.append(tokens[i].lemma_)\n",
    "            if tokens[i].pos_ in bigrams:\n",
    "                if (\n",
    "                    tokens[i - 1].pos_ in bigrams[tokens[i].pos_]\n",
    "                    or tokens[i - 1].lemma_ in bigrams[tokens[i].pos_]\n",
    "                ):\n",
    "                    preprocessed_words.append(\n",
    "                        tokens[i - 1].lemma_ + \" \" + tokens[i].lemma_\n",
    "                    )\n",
    "    return preprocessed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d599c",
   "metadata": {},
   "source": [
    "Пробуем снова посчитать тональности отзывов, запускаем код из предыдущей домашки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6742fc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"import requests\\nimport time\\nimport random\\nfrom fake_useragent import UserAgent\\nfrom bs4 import BeautifulSoup\\n\\npositive = []\\nnegative = []\\n\\nsession = requests.session()\\n\\nua = UserAgent(verify_ssl=False)\\nheaders = {\\\"User-Agent\\\": ua.random}\\nrandom.uniform(1, 3)\\n\\nfor num in range(19):\\n    for _ in range(5):\\n        response = session.get(f\\\"https://www.metacritic.com/game/pc/minecraft/user-reviews?page={num}\\\", headers = headers)\\n        time.sleep(random.uniform(1.1, 5.2))\\n\\n    page = response.text\\n    soup = BeautifulSoup(page, \\\"html.parser\\\")\\n    page_text = soup.find_all(\\\"div\\\", {\\\"class\\\": \\\"review_section\\\"})\\n\\n    for i in page_text:\\n        try: # \\u0438\\u0437\\u0431\\u0435\\u0433\\u0430\\u0435\\u043c \\u043e\\u0448\\u0438\\u0431\\u043a\\u0438 None has no attribute text, \\u043a\\u043e\\u0433\\u0434\\u0430 \\u0432\\u0441\\u0442\\u0440\\u0435\\u0447\\u0430\\u0435\\u043c \\u0441\\u043c\\u0435\\u0448\\u0430\\u043d\\u043d\\u044b\\u0435 \\u043e\\u0442\\u0437\\u044b\\u0432\\u044b\\n            if i.find(\\\"div\\\", {\\\"class\\\": \\\"metascore_w user medium game positive indiv\\\"}):\\n                try:\\n                    positive.append(i.find(\\\"span\\\", {\\\"class\\\": \\\"blurb blurb_expanded\\\"}).text) # \\u0435\\u0441\\u043b\\u0438 \\u0435\\u0441\\u0442\\u044c \\u043f\\u043e\\u043b\\u043d\\u0430\\u044f \\u0432\\u0435\\u0440\\u0441\\u0438\\u044f \\u043e\\u0442\\u0437\\u044b\\u0432\\u0430, \\u043f\\u044b\\u0442\\u0430\\u0435\\u043c\\u0441\\u044f \\u0441\\u043a\\u0430\\u0447\\u0430\\u0442\\u044c \\u0435\\u0451\\n                except:\\n                    positive.append(i.find(\\\"div\\\", {\\\"class\\\": \\\"review_body\\\"}).text)\\n            elif i.find(\\\"div\\\", {\\\"class\\\": \\\"metascore_w user medium game negative indiv\\\"}):\\n                try:\\n                    negative.append(i.find(\\\"span\\\", {\\\"class\\\": \\\"blurb blurb_expanded\\\"}).text) # \\u0435\\u0441\\u043b\\u0438 \\u0435\\u0441\\u0442\\u044c \\u043f\\u043e\\u043b\\u043d\\u0430\\u044f \\u0432\\u0435\\u0440\\u0441\\u0438\\u044f \\u043e\\u0442\\u0437\\u044b\\u0432\\u0430, \\u043f\\u044b\\u0442\\u0430\\u0435\\u043c\\u0441\\u044f \\u0441\\u043a\\u0430\\u0447\\u0430\\u0442\\u044c \\u0435\\u0451\\n                except:\\n                    negative.append(i.find(\\\"div\\\", {\\\"class\\\": \\\"review_body\\\"}).text)\\n        except:\\n            continue\";\n",
       "                var nbb_formatted_code = \"import requests\\nimport time\\nimport random\\nfrom fake_useragent import UserAgent\\nfrom bs4 import BeautifulSoup\\n\\npositive = []\\nnegative = []\\n\\nsession = requests.session()\\n\\nua = UserAgent(verify_ssl=False)\\nheaders = {\\\"User-Agent\\\": ua.random}\\nrandom.uniform(1, 3)\\n\\nfor num in range(19):\\n    for _ in range(5):\\n        response = session.get(\\n            f\\\"https://www.metacritic.com/game/pc/minecraft/user-reviews?page={num}\\\",\\n            headers=headers,\\n        )\\n        time.sleep(random.uniform(1.1, 5.2))\\n\\n    page = response.text\\n    soup = BeautifulSoup(page, \\\"html.parser\\\")\\n    page_text = soup.find_all(\\\"div\\\", {\\\"class\\\": \\\"review_section\\\"})\\n\\n    for i in page_text:\\n        try:  # \\u0438\\u0437\\u0431\\u0435\\u0433\\u0430\\u0435\\u043c \\u043e\\u0448\\u0438\\u0431\\u043a\\u0438 None has no attribute text, \\u043a\\u043e\\u0433\\u0434\\u0430 \\u0432\\u0441\\u0442\\u0440\\u0435\\u0447\\u0430\\u0435\\u043c \\u0441\\u043c\\u0435\\u0448\\u0430\\u043d\\u043d\\u044b\\u0435 \\u043e\\u0442\\u0437\\u044b\\u0432\\u044b\\n            if i.find(\\\"div\\\", {\\\"class\\\": \\\"metascore_w user medium game positive indiv\\\"}):\\n                try:\\n                    positive.append(\\n                        i.find(\\\"span\\\", {\\\"class\\\": \\\"blurb blurb_expanded\\\"}).text\\n                    )  # \\u0435\\u0441\\u043b\\u0438 \\u0435\\u0441\\u0442\\u044c \\u043f\\u043e\\u043b\\u043d\\u0430\\u044f \\u0432\\u0435\\u0440\\u0441\\u0438\\u044f \\u043e\\u0442\\u0437\\u044b\\u0432\\u0430, \\u043f\\u044b\\u0442\\u0430\\u0435\\u043c\\u0441\\u044f \\u0441\\u043a\\u0430\\u0447\\u0430\\u0442\\u044c \\u0435\\u0451\\n                except:\\n                    positive.append(i.find(\\\"div\\\", {\\\"class\\\": \\\"review_body\\\"}).text)\\n            elif i.find(\\n                \\\"div\\\", {\\\"class\\\": \\\"metascore_w user medium game negative indiv\\\"}\\n            ):\\n                try:\\n                    negative.append(\\n                        i.find(\\\"span\\\", {\\\"class\\\": \\\"blurb blurb_expanded\\\"}).text\\n                    )  # \\u0435\\u0441\\u043b\\u0438 \\u0435\\u0441\\u0442\\u044c \\u043f\\u043e\\u043b\\u043d\\u0430\\u044f \\u0432\\u0435\\u0440\\u0441\\u0438\\u044f \\u043e\\u0442\\u0437\\u044b\\u0432\\u0430, \\u043f\\u044b\\u0442\\u0430\\u0435\\u043c\\u0441\\u044f \\u0441\\u043a\\u0430\\u0447\\u0430\\u0442\\u044c \\u0435\\u0451\\n                except:\\n                    negative.append(i.find(\\\"div\\\", {\\\"class\\\": \\\"review_body\\\"}).text)\\n        except:\\n            continue\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import random\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "positive = []\n",
    "negative = []\n",
    "\n",
    "session = requests.session()\n",
    "\n",
    "ua = UserAgent(verify_ssl=False)\n",
    "headers = {\"User-Agent\": ua.random}\n",
    "random.uniform(1, 3)\n",
    "\n",
    "for num in range(19):\n",
    "    for _ in range(5):\n",
    "        response = session.get(\n",
    "            f\"https://www.metacritic.com/game/pc/minecraft/user-reviews?page={num}\",\n",
    "            headers=headers,\n",
    "        )\n",
    "        time.sleep(random.uniform(1.1, 5.2))\n",
    "\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    page_text = soup.find_all(\"div\", {\"class\": \"review_section\"})\n",
    "\n",
    "    for i in page_text:\n",
    "        try:  # избегаем ошибки None has no attribute text, когда встречаем смешанные отзывы\n",
    "            if i.find(\"div\", {\"class\": \"metascore_w user medium game positive indiv\"}):\n",
    "                try:\n",
    "                    positive.append(\n",
    "                        i.find(\"span\", {\"class\": \"blurb blurb_expanded\"}).text\n",
    "                    )  # если есть полная версия отзыва, пытаемся скачать её\n",
    "                except:\n",
    "                    positive.append(i.find(\"div\", {\"class\": \"review_body\"}).text)\n",
    "            elif i.find(\n",
    "                \"div\", {\"class\": \"metascore_w user medium game negative indiv\"}\n",
    "            ):\n",
    "                try:\n",
    "                    negative.append(\n",
    "                        i.find(\"span\", {\"class\": \"blurb blurb_expanded\"}).text\n",
    "                    )  # если есть полная версия отзыва, пытаемся скачать её\n",
    "                except:\n",
    "                    negative.append(i.find(\"div\", {\"class\": \"review_body\"}).text)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7983dd",
   "metadata": {},
   "source": [
    "#### Уравниваем кол-во отзывов, откладывыем по 10 из каждого списка на тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "693212eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"positive = positive[:len(negative)] # \\u0443\\u0440\\u0430\\u0432\\u043d\\u0438\\u0432\\u0430\\u0435\\u043c \\u043a\\u043e\\u043b-\\u0432\\u043e \\u0442\\u0435\\u043a\\u0441\\u0442\\u043e\\u0432\";\n",
       "                var nbb_formatted_code = \"positive = positive[: len(negative)]  # \\u0443\\u0440\\u0430\\u0432\\u043d\\u0438\\u0432\\u0430\\u0435\\u043c \\u043a\\u043e\\u043b-\\u0432\\u043e \\u0442\\u0435\\u043a\\u0441\\u0442\\u043e\\u0432\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive = positive[: len(negative)]  # уравниваем кол-во текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0ef5bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"test = {}\\nfor i in range(-1, -11, -1):\\n    test[positive.pop(i)] = \\\"positive\\\"\\n    test[negative.pop(i)] = \\\"negative\\\"\";\n",
       "                var nbb_formatted_code = \"test = {}\\nfor i in range(-1, -11, -1):\\n    test[positive.pop(i)] = \\\"positive\\\"\\n    test[negative.pop(i)] = \\\"negative\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = {}\n",
    "for i in range(-1, -11, -1):\n",
    "    test[positive.pop(i)] = \"positive\"\n",
    "    test[negative.pop(i)] = \"negative\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a5a28b",
   "metadata": {},
   "source": [
    "Считаем кол-во слов в каждом списке, убираем те, которые встречаются менее трёх раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a14d9622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"from collections import Counter\";\n",
       "                var nbb_formatted_code = \"from collections import Counter\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0099c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"def deleting_unpopular(preprocessed_list):\\n    word_list = []\\n    cnt_dict = Counter(preprocessing_with_bigrams(preprocessed_list))\\n    for i in cnt_dict:\\n        if cnt_dict[i] > 2:\\n            word_list.append(i)\\n    return set(word_list)\";\n",
       "                var nbb_formatted_code = \"def deleting_unpopular(preprocessed_list):\\n    word_list = []\\n    cnt_dict = Counter(preprocessing_with_bigrams(preprocessed_list))\\n    for i in cnt_dict:\\n        if cnt_dict[i] > 2:\\n            word_list.append(i)\\n    return set(word_list)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def deleting_unpopular(preprocessed_list):\n",
    "    word_list = []\n",
    "    cnt_dict = Counter(preprocessing_with_bigrams(preprocessed_list))\n",
    "    for i in cnt_dict:\n",
    "        if cnt_dict[i] > 2:\n",
    "            word_list.append(i)\n",
    "    return set(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cd2cbf",
   "metadata": {},
   "source": [
    "Удаляем слова, которые есть и в позитивных, и в негативных отзывах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd4aabbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"positive_set = deleting_unpopular(positive)\";\n",
       "                var nbb_formatted_code = \"positive_set = deleting_unpopular(positive)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_set = deleting_unpopular(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80b8d0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"negative_set = deleting_unpopular(negative)\";\n",
       "                var nbb_formatted_code = \"negative_set = deleting_unpopular(negative)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "negative_set = deleting_unpopular(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b4c8240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"intersection = positive_set.intersection(negative_set)\\npositive_set.difference_update(intersection)\\nnegative_set.difference_update(intersection)\";\n",
       "                var nbb_formatted_code = \"intersection = positive_set.intersection(negative_set)\\npositive_set.difference_update(intersection)\\nnegative_set.difference_update(intersection)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "intersection = positive_set.intersection(negative_set)\n",
    "positive_set.difference_update(intersection)\n",
    "negative_set.difference_update(intersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcbeb7e",
   "metadata": {},
   "source": [
    "Функция для определения тональности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7864e53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"freq_lists = {}\\n\\nfreq_lists[\\\"positive\\\"] = positive_set\\nfreq_lists[\\\"negative\\\"] = negative_set\";\n",
       "                var nbb_formatted_code = \"freq_lists = {}\\n\\nfreq_lists[\\\"positive\\\"] = positive_set\\nfreq_lists[\\\"negative\\\"] = negative_set\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "freq_lists = {}\n",
    "\n",
    "freq_lists[\"positive\"] = positive_set\n",
    "freq_lists[\"negative\"] = negative_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12588947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"def simple_sent_analysis(freq_lists, text):\\n    preprocessed_review_list = []\\n    preprocessed_review = nlp(text.lower()) # \\u0437\\u0434\\u0435\\u0441\\u044c \\u0442\\u0435\\u043a\\u0441\\u0442 \\u0443\\u0436\\u0435 \\u0434\\u0435\\u043b\\u0438\\u0442\\u0441\\u044f \\u043f\\u043e \\u043f\\u0440\\u0435\\u0434\\u043b\\u043e\\u0436\\u0435\\u043d\\u0438\\u044f\\u043c \\u0438 \\u0442\\u043e\\u043a\\u0435\\u043d\\u0438\\u0437\\u0438\\u0440\\u0443\\u0435\\u0442\\u0441\\u044f\\n    for word in [token.lemma_ for token in preprocessed_review if not token.is_punct]:\\n        if word.isalpha:\\n            preprocessed_review_list.append(word)\\n    counts = Counter()\\n    for tone, freq_list in freq_lists.items():\\n        freq_list = Counter(freq_list)\\n        for word in preprocessed_review_list:\\n            counts[tone] += int(freq_list[word] > 0)\\n    return counts.most_common()[0][0]\";\n",
       "                var nbb_formatted_code = \"def simple_sent_analysis(freq_lists, text):\\n    preprocessed_review_list = []\\n    preprocessed_review = nlp(\\n        text.lower()\\n    )  # \\u0437\\u0434\\u0435\\u0441\\u044c \\u0442\\u0435\\u043a\\u0441\\u0442 \\u0443\\u0436\\u0435 \\u0434\\u0435\\u043b\\u0438\\u0442\\u0441\\u044f \\u043f\\u043e \\u043f\\u0440\\u0435\\u0434\\u043b\\u043e\\u0436\\u0435\\u043d\\u0438\\u044f\\u043c \\u0438 \\u0442\\u043e\\u043a\\u0435\\u043d\\u0438\\u0437\\u0438\\u0440\\u0443\\u0435\\u0442\\u0441\\u044f\\n    for word in [token.lemma_ for token in preprocessed_review if not token.is_punct]:\\n        if word.isalpha:\\n            preprocessed_review_list.append(word)\\n    counts = Counter()\\n    for tone, freq_list in freq_lists.items():\\n        freq_list = Counter(freq_list)\\n        for word in preprocessed_review_list:\\n            counts[tone] += int(freq_list[word] > 0)\\n    return counts.most_common()[0][0]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def simple_sent_analysis(freq_lists, text):\n",
    "    preprocessed_review_list = []\n",
    "    preprocessed_review = nlp(\n",
    "        text.lower()\n",
    "    )  # здесь текст уже делится по предложениям и токенизируется\n",
    "    for word in [token.lemma_ for token in preprocessed_review if not token.is_punct]:\n",
    "        if word.isalpha:\n",
    "            preprocessed_review_list.append(word)\n",
    "    counts = Counter()\n",
    "    for tone, freq_list in freq_lists.items():\n",
    "        freq_list = Counter(freq_list)\n",
    "        for word in preprocessed_review_list:\n",
    "            counts[tone] += int(freq_list[word] > 0)\n",
    "    return counts.most_common()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74569cd",
   "metadata": {},
   "source": [
    "Запущенная функция + тональность отзыва:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09e54581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive positive\n",
      "negative negative\n",
      "negative positive\n",
      "negative negative\n",
      "positive positive\n",
      "negative negative\n",
      "positive positive\n",
      "negative negative\n",
      "positive positive\n",
      "positive negative\n",
      "positive positive\n",
      "negative negative\n",
      "positive positive\n",
      "negative negative\n",
      "positive positive\n",
      "positive negative\n",
      "negative positive\n",
      "positive negative\n",
      "positive positive\n",
      "negative negative\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"for i in test:\\n    print(simple_sent_analysis(freq_lists, i), test[i])\";\n",
       "                var nbb_formatted_code = \"for i in test:\\n    print(simple_sent_analysis(freq_lists, i), test[i])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in test:\n",
    "    print(simple_sent_analysis(freq_lists, i), test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2fcdc8",
   "metadata": {},
   "source": [
    "Подсчёт accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93ab4b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"def test_simple_sent_analysis(freq_lists, test_list):\\n    results = []\\n    gold = []\\n    for tone in freq_lists:\\n        for text in test_list:\\n            predicted_tone = simple_sent_analysis(freq_lists, text)\\n            results.append(predicted_tone)\\n            gold.append(test_list[text])\\n    print(\\\"RESULTS:\\\")\\n    print(\\\"Accuracy: %.4f\\\" % accuracy_score(results, gold))\";\n",
       "                var nbb_formatted_code = \"def test_simple_sent_analysis(freq_lists, test_list):\\n    results = []\\n    gold = []\\n    for tone in freq_lists:\\n        for text in test_list:\\n            predicted_tone = simple_sent_analysis(freq_lists, text)\\n            results.append(predicted_tone)\\n            gold.append(test_list[text])\\n    print(\\\"RESULTS:\\\")\\n    print(\\\"Accuracy: %.4f\\\" % accuracy_score(results, gold))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_simple_sent_analysis(freq_lists, test_list):\n",
    "    results = []\n",
    "    gold = []\n",
    "    for tone in freq_lists:\n",
    "        for text in test_list:\n",
    "            predicted_tone = simple_sent_analysis(freq_lists, text)\n",
    "            results.append(predicted_tone)\n",
    "            gold.append(test_list[text])\n",
    "    print(\"RESULTS:\")\n",
    "    print(\"Accuracy: %.4f\" % accuracy_score(results, gold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31bb6b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:\n",
      "Accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"test_simple_sent_analysis(freq_lists, test)\";\n",
       "                var nbb_formatted_code = \"test_simple_sent_analysis(freq_lists, test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_simple_sent_analysis(freq_lists, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f105eab",
   "metadata": {},
   "source": [
    "Accuracy повысилась на 10%, ура!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
